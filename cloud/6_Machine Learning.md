### Machine Learning

1. 이진 트리 (10개 종류): *찾아봄*
    - 포화 이진 트리 (Perfect Binary Tree): 모든 레벨이 완전히 채워진 트리입니다.
    - 완전 이진 트리 (Complete Binary Tree): 마지막 레벨을 제외한 모든 레벨이 완전히 채워져 있고, 마지막 레벨의 노드들은 왼쪽부터 채워진 트리입니다.
    - 정 이진 트리 (Full Binary Tree): 모든 노드가 0개 또는 2개의 자식 노드를 가지는 트리입니다.
    - 편향 이진 트리 (Skewed Binary Tree): 모든 노드가 한쪽 방향(왼쪽 또는 오른쪽)으로만 자식 노드를 가지는 트리입니다.
    - 균형 이진 트리 (Balanced Binary Tree): 모든 노드의 왼쪽과 오른쪽 서브트리의 높이 차이가 1 이하인 트리입니다.
    - 이진 탐색 트리 (Binary Search Tree): 왼쪽 자식 노드는 부모 노드보다 작고, 오른쪽 자식 노드는 부모 노드보다 큰 값을 가지는 트리입니다.
    - AVL 트리 (AVL Tree): 모든 노드의 왼쪽과 오른쪽 서브트리의 높이 차이가 1 이하인 이진 탐색 트리입니다.
    - 레드-블랙 트리 (Red-Black Tree): 각 노드가 빨간색 또는 검은색으로 색칠된 이진 탐색 트리로, 특정 규칙을 따라 균형을 유지합니다.
    - B 트리 (B-Tree): 자식 노드의 수가 2개 이상인 트리로, 데이터베이스와 파일 시스템에서 자주 사용됩니다.
    - 힙 트리 (Heap Tree): 부모 노드가 자식 노드보다 항상 크거나 작은 값을 가지는 트리입니다. 최대 힙과 최소 힙으로 나뉩니다.

2. 인공지능 < 머신러닝 < **딥러닝**
    - 머신러닝: 데이터 학습
    - 딥러닝 : **인공신경망** 방식으로 정보를 처리
        - 인공신경망: 인간의 뇌 신경망
        - CNN, Layer 형태

3. 빅데이터 > 클라우드 컴퓨팅 > 딥러닝 알고리즘
    - 글라디오 기반의 스테이블 디퓨전

4. 머신 러닝
    - 규칙을 파악
    - 새로운 영화를 좋아하는 지 예측

5. 지도학습 / 비지도 학습
    - 지도학습 (Supervised Learning) : Output이 있다. **(명확한 Output)**
    - 비지도학습 (Unsupervised Learning) : Output이 없다.

6. 지도학습
    - 회귀 (Regression): **수칙 예측**
    - 분류 (Classification): 범주 예측

7. 비지도학습
    - 군집 (Clustering): 문서 구분, IOT기기 구입.
    - 연관 (Association): 쿠팡 연관 특징

8. 분류 (Classification)
    - 2진 분류: 스팸 메일, 필터링, 질병 진단
    - 다중 클래스
        - 서포트 벡터 머신 (SVM): 최적의 분할선
        - 의사 결졍 나무 (Decision Tree)
        - 로지스틱 회귀

9. 특성 (feature)
    - Input

10. 정답 (Label)
    - Output

11. 범주 클라스 (class)

13. 문제 정의 > 데이터 수집 및 이해 > 데이터 준비 > 데이터 모델링 > 모델링 평가

14. 데이터 준비
    - 데이터 전처리
    - 데이터 분리 (7:3으로)

15. 알고리즘: **의사결정 나무** (Decision Tree)
    - x,y로 나눔
    - 노드 (node)
    - 루트 노드 (root node)
    - 리프 노드 (leaf node)
    - 부모 노드 (parent node)
    - 자식 노드 (child node)
    
16. 불순도 (impurity)
    - 불순도가 높음: 결과 예측이 어려움
    - 불순도가 낮음: 결과 예측이 용이함

17. 지니 불순도 (Gini Impurity)
    - 지니 불순도 = 1 - (초록 비율^2 + 빨강 비율^2)

18. 나무 형태로 시각화

19. Depth를 보통 30개까지 한다.

20. 과대 적합
    - 오히려 예측이 떨어짐
    - Depth 6번: 초록은 너무 많이 나눴음
    - Depth 2번: 빨강이 더 정확

21. **랜덤 포레스트**
    - 단순하면서 강력한 분류
    - 알고리즘으로 평가 받고 있음

22. 앙상블 (Ensemble learning)

23. 랜덤 포레스트 (Random Forest)
    - 복수를 허용하는지 안하는지에 따라서 결과가 다르게 나옴

24. **배깅 (Bagging)**
    - 뽑히는데, 중복을 허용한다.

25. **페이스팅 (Pasting)**
    - 동일한 값은 뽑히지 않는다.

26. 진행해 봐야 알 수도 있다.

27. 하이퍼 파리미터
    - 의사 결정나무 최대 깊이 (max depth)
    - 랜덤포레스트 샘플링 시 중복 허용

EOF 